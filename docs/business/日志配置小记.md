## logback

### 1.pom依赖

```xml
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
</dependencies>
```

### 2.application.properties文件的配置

```properties
logging.config=classpath:logback-spring.xml
```

### 3.logback-spring.xml文件配置

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <property name="LOG_HOME" value="./log"/>
    <!-- %m输出的信息,%p日志级别,%t线程名,%d日期,%c类的全名,%i索引【从数字0开始递增】,,, -->
    <!-- appender是configuration的子节点，是负责写日志的组件。 -->
    <!-- ConsoleAppender：把日志输出到控制台 -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</pattern>
            <!-- 控制台也要使用UTF-8，不要使用GBK，否则会中文乱码 -->
            <charset>UTF-8</charset>
        </encoder>
    </appender>

    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">

        <File>${LOG_HOME}/cap.log</File>
        <!-- 根据时间来制定滚动策略 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <FileNamePattern>
                ${LOG_HOME}/cap.%d{yyyy-MM-dd}.%i.log
            </FileNamePattern>
            <!-- 多久后自动清楚旧的日志文件,单位:日 -->
            <MaxHistory>7</MaxHistory>
            <!-- each file should be at most 10MB, keep 30 days worth of history,
            but at most 3GB -->
            <maxFileSize>200MB</maxFileSize>
            <maxHistory>7</maxHistory>
<!--            <totalSizeCap>3GB</totalSizeCap>-->
        </rollingPolicy>
        <encoder>
            <Pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n</Pattern>
        </encoder>
    </appender>


    <root level="DEBUG">
        <appender-ref ref="STDOUT" />
        <appender-ref ref="FILE" />
    </root>

    <root level="INFO">
        <appender-ref ref="STDOUT" />
        <appender-ref ref="FILE" />
    </root>
</configuration>
```

### 4.配置mybatis完成SQL性能分析

```java
package com.hichain.capwms.config.mybatisplus;

import com.baomidou.mybatisplus.core.toolkit.CollectionUtils;
import com.baomidou.mybatisplus.core.toolkit.PluginUtils;
import com.baomidou.mybatisplus.core.toolkit.StringPool;
import com.baomidou.mybatisplus.core.toolkit.SystemClock;
import com.baomidou.mybatisplus.core.toolkit.sql.SqlUtils;
import lombok.extern.slf4j.Slf4j;
import org.apache.ibatis.executor.statement.StatementHandler;
import org.apache.ibatis.mapping.BoundSql;
import org.apache.ibatis.mapping.MappedStatement;
import org.apache.ibatis.mapping.ParameterMapping;
import org.apache.ibatis.plugin.*;
import org.apache.ibatis.reflection.MetaObject;
import org.apache.ibatis.reflection.SystemMetaObject;
import org.apache.ibatis.session.Configuration;
import org.apache.ibatis.session.ResultHandler;
import org.apache.ibatis.type.TypeHandlerRegistry;

import java.lang.reflect.Method;
import java.lang.reflect.Proxy;
import java.sql.Statement;
import java.text.DateFormat;
import java.util.*;

/**
 * 性能分析拦截器，用于输出每条 SQL 语句及其执行时间
 * 去除sql语句有问号
 * @author chenfeng
 * @since 2021年2月22日
 */
@Intercepts({@Signature(
        type = StatementHandler.class,
        method = "query",
        args = {Statement.class, ResultHandler.class}
), @Signature(
        type = StatementHandler.class,
        method = "update",
        args = {Statement.class}
), @Signature(
        type = StatementHandler.class,
        method = "batch",
        args = {Statement.class}
)})
@Slf4j
public class PerformanceInterceptor  implements Interceptor {

    private static final String DruidPooledPreparedStatement = "com.alibaba.druid.pool.DruidPooledPreparedStatement";
    private static final String T4CPreparedStatement = "oracle.jdbc.driver.T4CPreparedStatement";
    private static final String OraclePreparedStatementWrapper = "oracle.jdbc.driver.OraclePreparedStatementWrapper";
    private long maxTime = 0L;
    private boolean format = false;
    private boolean writeInLog = false;
    private Method oracleGetOriginalSqlMethod;
    private Method druidGetSQLMethod;

    @Override
    public Object intercept(Invocation invocation) throws Throwable {

        Object firstArg = invocation.getArgs()[0];
        Statement statement;
        if (Proxy.isProxyClass(firstArg.getClass())) {
            statement = (Statement)SystemMetaObject.forObject(firstArg).getValue("h.statement");
        } else {
            statement = (Statement)firstArg;
        }

        MetaObject stmtMetaObj = SystemMetaObject.forObject(statement);

        try {
            statement = (Statement)stmtMetaObj.getValue("stmt.statement");
        } catch (Exception var20) {
        }

        if (stmtMetaObj.hasGetter("delegate")) {
            try {
                statement = (Statement)stmtMetaObj.getValue("delegate");
            } catch (Exception var19) {
            }
        }

        String originalSql = null;
        String stmtClassName = statement.getClass().getName();
        Class clazz;
        Object stmtSql;
        if ("com.alibaba.druid.pool.DruidPooledPreparedStatement".equals(stmtClassName)) {
            try {
                if (this.druidGetSQLMethod == null) {
                    clazz = Class.forName("com.alibaba.druid.pool.DruidPooledPreparedStatement");
                    this.druidGetSQLMethod = clazz.getMethod("getSql");
                }

                stmtSql = this.druidGetSQLMethod.invoke(statement);
                if (stmtSql instanceof String) {
                    originalSql = (String)stmtSql;
                }
            } catch (Exception var18) {
                var18.printStackTrace();
            }
        } else if ("oracle.jdbc.driver.T4CPreparedStatement".equals(stmtClassName) || "oracle.jdbc.driver.OraclePreparedStatementWrapper".equals(stmtClassName)) {
            try {
                if (this.oracleGetOriginalSqlMethod != null) {
                    stmtSql = this.oracleGetOriginalSqlMethod.invoke(statement);
                    if (stmtSql instanceof String) {
                        originalSql = (String)stmtSql;
                    }
                } else {
                    clazz = Class.forName(stmtClassName);
                    this.oracleGetOriginalSqlMethod = this.getMethodRegular(clazz, "getOriginalSql");
                    if (this.oracleGetOriginalSqlMethod != null) {
                        this.oracleGetOriginalSqlMethod.setAccessible(true);
                        if (null != this.oracleGetOriginalSqlMethod) {
                            Object stmt = this.oracleGetOriginalSqlMethod.invoke(statement);
                            if (stmt instanceof String) {
                                originalSql = (String)stmt;
                            }
                        }
                    }
                }
            } catch (Exception var17) {
            }
        }

        if (originalSql == null) {
            originalSql = statement.toString();
        }

        originalSql = originalSql.replaceAll("[\\s]+", " ");
        int index = this.indexOfSqlStart(originalSql);
        if (index > 0) {
            originalSql = originalSql.substring(index);
        }

        long start = SystemClock.now();
        Object result = invocation.proceed();
        long timing = SystemClock.now() - start;
        Object target = PluginUtils.realTarget(invocation.getTarget());
        MetaObject metaObject = SystemMetaObject.forObject(target);
        MappedStatement ms = (MappedStatement)metaObject.getValue("delegate.mappedStatement");
        StringBuilder formatSql = (new StringBuilder()).append(" Time：").append(timing).append(" ms - ID：").append(ms.getId()).append("\n").append("Execute SQL：").append(SqlUtils.sqlFormat(originalSql, this.format)).append("\n");
        log.info(formatSql.toString());
        return result;
    }

    private static void showSql(Configuration configuration, BoundSql boundSql, long time, String sqlId) {
        Object parameterObject = boundSql.getParameterObject();
        List<ParameterMapping> parameterMappings = boundSql.getParameterMappings();
        //替换空格、换行、tab缩进等
        String sql = boundSql.getSql().replaceAll("[\\s]+", " ");
        if (parameterMappings.size() > 0 && parameterObject != null) {
            TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry();
            if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) {
                sql = sql.replaceFirst("\\?", getParameterValue(parameterObject));
            } else {
                MetaObject metaObject = configuration.newMetaObject(parameterObject);
                for (ParameterMapping parameterMapping : parameterMappings) {
                    String propertyName = parameterMapping.getProperty();
                    if (metaObject.hasGetter(propertyName)) {
                        Object obj = metaObject.getValue(propertyName);
                        sql = sql.replaceFirst("\\?", getParameterValue(obj));
                    } else if (boundSql.hasAdditionalParameter(propertyName)) {
                        Object obj = boundSql.getAdditionalParameter(propertyName);
                        sql = sql.replaceFirst("\\?", getParameterValue(obj));
                    }
                }
            }
        }
        logs(time, sql, sqlId);
    }

    private static String getParameterValue(Object obj) {
        String value;
        if (obj instanceof String) {
            value = "'" + obj.toString() + "'";
        } else if (obj instanceof Date) {
            DateFormat formatter = DateFormat.getDateTimeInstance(DateFormat.DEFAULT, DateFormat.DEFAULT, Locale.CHINA);
            value = "'" + formatter.format(new Date()) + "'";
        } else {
            if (obj != null) {
                value = obj.toString();
            } else {
                value = "";
            }
        }
        return value.replace("$", "\\$");
    }

    private static void logs(long time, String sql, String sqlId) {
        StringBuilder sb = new StringBuilder()
                .append(" Time：").append(time)
                .append(" ms - ID：").append(sqlId)
                .append(StringPool.NEWLINE).append("Execute SQL：")
                .append(sql).append(StringPool.NEWLINE);
        log.info(sb.toString());
    }

    @Override
    public Object plugin(Object target) {
        return Plugin.wrap(target, this);
    }

    @Override
    public void setProperties(Properties properties0) {
    }


    public Method getMethodRegular(Class<?> clazz, String methodName) {
        if (Object.class.equals(clazz)) {
            return null;
        } else {
            Method[] var3 = clazz.getDeclaredMethods();
            int var4 = var3.length;

            for(int var5 = 0; var5 < var4; ++var5) {
                Method method = var3[var5];
                if (method.getName().equals(methodName)) {
                    return method;
                }
            }

            return this.getMethodRegular(clazz.getSuperclass(), methodName);
        }
    }

    private int indexOfSqlStart(String sql) {
        String upperCaseSql = sql.toUpperCase();
        Set<Integer> set = new HashSet();
        set.add(upperCaseSql.indexOf("SELECT "));
        set.add(upperCaseSql.indexOf("UPDATE "));
        set.add(upperCaseSql.indexOf("INSERT "));
        set.add(upperCaseSql.indexOf("DELETE "));
        set.remove(-1);
        if (CollectionUtils.isEmpty(set)) {
            return -1;
        } else {
            List<Integer> list = new ArrayList(set);
            list.sort(Comparator.naturalOrder());
            return (Integer)list.get(0);
        }
    }
}

```



### logback配置文件详解

#### 1. 根标签

`<configuration>` 是 logback 配置文件的根标签，其所有的配置内容都要定义在`<configuration>`标签之内。`<configuration>`标签包含如下3个常用的属性：

- scan：当属性值为 true 时，如果配置文件的内容发现变化，则会重新加载配置文件，默认为 true。
- scanPeriod：设置监测配置文件变化的时间间隔，默认值为`60 seconds`，即60s，如果单位缺省，则默认单位为毫秒。另外，scanPeriod 只有在 scan 属性值为 true 时，才有效。
- debug：是否打印 logback 内部的运行日志，默认值为 false，一般无需关心 logback 的内部运行状况。

示例：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
</configuration>
```

#### 2. 变量定义

`<property/>` 标签用来定义变量，定义的变量可以在后续通过`${变量名}`的方式来引用，`<property/>` 标签有2个属性值：

- name：定义变量名称
- value：定义变量的值

示例：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <!-- 定义日志目录 -->
    <property name="DEBUG_LOG_PATH" value="logs/debug"/>
    <!-- 定义日志保留天数 -->
    <property name="MAX_HISTORY" value="7"/>
    <!-- 定义日志文件总大小 -->
    <property name="TOTAL_SIZE_CAP" value="10GB"/>
    <!-- 定义单个日志文件大小 -->
    <property name="MAX_FILE_SIZE" value="50MB"/>
</configuration>
```

#### 3. 日志输出

`<appender>` 标签用来配置日志的输出，是最重要的一个标签。`<appender>`标签有2个属性：

- name：指定 appender 的名称
- class：指定日志的输出策略，其中`ch.qos.logback.core.ConsoleAppender` 用来指定日志输出到控制台，`ch.qos.logback.core.rolling.RollingFileAppender` 用来指定日志输出到滚动文件

##### 3.1 日志格式

在`<encoder>` 标签用来格式化日志，`<encoder>`有2个子节点`<pattern>` 和 `<charset>`，`<pattern>`指定日志的格式，`<charset>` 用来指定编码。

示例：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <!-- 输出到控制台 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
</configuration>
```

**日志输出格式说明：**

- %d{yyyy-MM-dd HH:mm:ss}：表示日期，花括号中指定日期的格式为`yyyy-MM-dd HH:mm:ss`
- %thread：表示线程名
- %-5level：表示日志级别，-5表示从左显示5个字符宽度
- %logger{36}：表示 logger 的名称，36个字符宽度
- %msg：表示日志内容
- %n：表示换行

##### 3.2 日志文件名

`<file>`标签用来指定日志文件，可以是相对路径，也可以是绝对路径，如果上级目录不存在，会自动创建。`<file>` 标签只有当 appender 的日志输出策略为日志文件或者滚动文件时才能使用。

示例：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <!-- 定义日志目录 -->
    <property name="DEBUG_LOG_PATH" value="logs/debug"/>
    
    <!-- 输出到滚动文件 -->
    <appender name="DEBUG_LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${DEBUG_LOG_PATH}/output.log</file>
        <encoder>
            <!-- 日志输出格式 -->
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
</configuration>
```

##### 3.3 滚动策略

`<rollingPolicy>` 标签用来指定滚动策略， 所谓的滚动策略其实就是对日志文件进行归档。`<rollingPolicy>` 标签只有1个`class`属性，其常见的属性值如下：

- `ch.qos.logback.core.rolling.TimeBaseRollingPolicy`：基于时间的滚动策略
- `ch.qos.logback.core.rolling.SizeAndTimeBaseRollingPolicy`：基于文件大小和时间滚动策略

`<rollingPolicy>` 的子标签如下：

- `<fileNamePattern>`：指定归档后的日志文件名
- `<maxHistory>`：指定日志的保留天数
- `<totalSizeCap>`：指定归档文件的总大小，超过其指定的值后，旧的日志文件会被删除
- `<maxFileSize>`：指定日志文件的限制大小，在 "基于文件大小和时间滚动策略" 中使用

示例：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <!-- 定义日志目录 -->
    <property name="DEBUG_LOG_PATH" value="logs/debug"/>
    <!-- 定义日志保留天数 -->
    <property name="MAX_HISTORY" value="7"/>
    <!-- 定义日志文件总大小 -->
    <property name="TOTAL_SIZE_CAP" value="10GB"/>
    <!-- 定义单个日志文件大小 -->
    <property name="MAX_FILE_SIZE" value="50MB"/>
    
    <!-- 输出到控制台 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <!-- 日志输出格式 -->
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
    
    <!-- 输出到滚动文件 -->
    <appender name="DEBUG_LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${DEBUG_LOG_PATH}/output.log</file>
        <!-- 基于文件大小和时间的滚动策略 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${DEBUG_LOG_PATH}/output-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <!-- 日志文件保留天数 -->
            <maxHistory>${MAX_HISTORY}</maxHistory>
            <!-- 日志归档文件总大小 -->
            <totalSizeCap>${TOTAL_SIZE_CAP}</totalSizeCap>
            <!-- 单个日志文件大小 -->
            <maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
        </rollingPolicy>
        <!-- 日志输出格式 -->
        <encoder>
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
</configuration>
```

##### 3.4 日志过滤

日志级别：TRACE < DEBUG < INFO < WARN < ERROR

如果只需要记录特定的日志，则可以使用 `<filter>`标签对日志进行过略。`<filter>` 标签只有1个属性`class`，用来指定过略器。常用的过滤器有`LevelFilter`，即按照日志级别来过滤日志（其它的过滤器不做过多的研究）。

示例：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <!-- 定义日志目录 -->
    <property name="DEBUG_LOG_PATH" value="logs/debug"/>
    <!-- 定义日志保留天数 -->
    <property name="MAX_HISTORY" value="7"/>
    <!-- 定义日志文件总大小 -->
    <property name="TOTAL_SIZE_CAP" value="10GB"/>
    <!-- 定义单个日志文件大小 -->
    <property name="MAX_FILE_SIZE" value="50MB"/>
    
    <!-- 输出到控制台 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <!-- 日志输出格式 -->
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
    
    <!-- 输出DEBUG日志 -->
    <appender name="DEBUG_LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${DEBUG_LOG_PATH}/output.log</file>
        <!-- 基于文件大小和时间的滚动策略 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${DEBUG_LOG_PATH}/output-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <!-- 日志文件保留天数 -->
            <maxHistory>${MAX_HISTORY}</maxHistory>
            <!-- 日志归档文件总大小 -->
            <totalSizeCap>${TOTAL_SIZE_CAP}</totalSizeCap>
            <!-- 单个日志文件大小 -->
            <maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
        </rollingPolicy>
        <!-- 日志输出格式 -->
        <encoder>
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 指定日志级别 -->
            <level>DEBUG</level>
            <!-- 匹配则全部接受 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配则全部拒绝 -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
</configuration>
```

#### 4. root 与 logger

`<root>` 标签是配置文件中必选的标签，也是特殊的`<logger>`标签，用来指定基础的日志输出级别，`<root>` 标签只有1个属性`level`，用来指定日志级别，默认为`debug`。

`<logger>` 标签用来限定特定的包的日志输出级别，`appender`需要和`logger`进行绑定，否则定义的`appender`不会生效。(通过`<appender-ref/>` 中的`ref`属性进行绑定)。

`<logger>`有3个属性：

- name：必选属性，用来指定包名
- level：可选属性，用来指定日志级别，默认为`DEBUG`
- addtivity：是否向上级 logger(一般为 root) 传递日志输出，默认为 true。

> tips：如果 addtivity 的属性值为 true，则在当前 logger 所绑定的 appender 中的输出的日志，在 root 绑定的 appender 中也会输出

示例：

在下面例子中，输出到`INFO_LOG_FILE`中的日志，同样会输出到`CONSOLE` 和 `DEBUG_LOG_FILE` 这两个`appender`

```xml
<!-- root -->
<root level="DEBUG">
    <appender-ref ref="CONSOLE"/>
    <appender-ref ref="DEBUG_LOG_FILE"/>
</root>
<!-- logger -->
<logger name="com.example" level="INFO" addtivity="true">
    <appender-ref ref="INFO_LOG_FILE"/>
</logger>
```

#### 5. 多环境配置

在 SpringBoot 官网推荐 logback 的配置文件使用`*-spring.xml`的命名方式，这样在配置文件中就可以使用 SpringBoot 的一些特性，例如：不同的环境输出不同级别的日志。

`<springProfile>` 标签用来指定 SpringBoot 的配置文件，如下所示：

```xml
<!-- 指定profile为default和prod时的日志级别-->
<springProfile name="default,prod">
    <root level="ERROR">
        <appender-ref ref="ERROR_LOG_FILE"/>
    </root>
</springProfile>
<!-- 指定profile为dev和test时的日志级别-->
<springProfile name="dev,test">
    <root level="DEBUG">
        <appender-ref ref="CONSOLE"/>
        <appender-ref ref="DEBUG_LOG_FILE"/>
        <appender-ref ref="ERROR_LOG_FILE"/>
    </root>
</springProfile>
```

### 二、配置文件模板

下面是`logback-spring.xml`配置文件模板：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration scan="true" scanPeriod="60 seconds" debug="false">
    <!-- 定义日志目录 -->
    <property name="DEBUG_LOG_PATH" value="logs/debug"/>
    <property name="INFO_LOG_PATH" value="logs/info"/>
    <property name="WARN_LOG_PATH" value="logs/warn"/>
    <property name="ERROR_LOG_PATH" value="logs/error"/>
    <!-- 定义日志保留天数 -->
    <property name="MAX_HISTORY" value="7"/>
    <!-- 定义日志文件总大小 -->
    <property name="TOTAL_SIZE_CAP" value="10GB"/>
    <!-- 定义单个日志文件大小 -->
    <property name="MAX_FILE_SIZE" value="50MB"/>
   
    <!-- 输出到控制台 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <!-- 日志输出格式 -->
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
    </appender>
    
    <!-- 只输出DEBUG日志 -->
    <appender name="DEBUG_LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${DEBUG_LOG_PATH}/output.log</file>
        <!-- 基于文件大小和时间的滚动策略 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${DEBUG_LOG_PATH}/output-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <!-- 日志文件保留天数 -->
            <maxHistory>${MAX_HISTORY}</maxHistory>
            <!-- 日志归档文件总大小 -->
            <totalSizeCap>${TOTAL_SIZE_CAP}</totalSizeCap>
            <!-- 单个日志文件大小 -->
            <maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
        </rollingPolicy>
        <!-- 日志输出格式 -->
        <encoder>
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 指定日志级别 -->
            <level>DEBUG</level>
            <!-- 匹配则全部接受 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配则全部拒绝 -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
    
    <!-- 只输出INFO日志 -->
    <appender name="INFO_LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${INFO_LOG_PATH}/output.log</file>
        <!-- 基于文件大小和时间的滚动策略 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${INFO_LOG_PATH}/output-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <!-- 日志文件保留天数 -->
            <maxHistory>${MAX_HISTORY}</maxHistory>
            <!-- 日志归档文件总大小 -->
            <totalSizeCap>${TOTAL_SIZE_CAP}</totalSizeCap>
            <!-- 单个日志文件大小 -->
            <maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
        </rollingPolicy>
        <!-- 日志输出格式 -->
        <encoder>
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 指定日志级别 -->
            <level>INFO</level>
            <!-- 匹配则全部接受 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配则全部拒绝 -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
    
    <!-- 只输出WARN日志 -->
    <appender name="WARN_LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${WARN_LOG_PATH}/output.log</file>
        <!-- 基于文件大小和时间的滚动策略 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${WARN_LOG_PATH}/output-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <!-- 日志文件保留天数 -->
            <maxHistory>${MAX_HISTORY}</maxHistory>
            <!-- 日志归档文件总大小 -->
            <totalSizeCap>${TOTAL_SIZE_CAP}</totalSizeCap>
            <!-- 单个日志文件大小 -->
            <maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
        </rollingPolicy>
        <!-- 日志输出格式 -->
        <encoder>
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 指定日志级别 -->
            <level>WARN</level>
            <!-- 匹配则全部接受 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配则全部拒绝 -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
    
    <!-- 只输出ERROR日志 -->
    <appender name="ERROR_LOG_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${ERROR_LOG_PATH}/output.log</file>
        <!-- 基于文件大小和时间的滚动策略 -->
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${ERROR_LOG_PATH}/output-%d{yyyy-MM-dd}-%i.log</fileNamePattern>
            <!-- 日志文件保留天数 -->
            <maxHistory>${MAX_HISTORY}</maxHistory>
            <!-- 日志归档文件总大小 -->
            <totalSizeCap>${TOTAL_SIZE_CAP}</totalSizeCap>
            <!-- 单个日志文件大小 -->
            <maxFileSize>${MAX_FILE_SIZE}</maxFileSize>
        </rollingPolicy>
        <!-- 日志输出格式 -->
        <encoder>
            <pattern>[%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36}: %msg%n</pattern>
            <charset>UTF-8</charset>
        </encoder>
        <!-- 日志过滤 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <!-- 指定日志级别 -->
            <level>ERROR</level>
            <!-- 匹配则全部接受 -->
            <onMatch>ACCEPT</onMatch>
            <!-- 不匹配则全部拒绝 -->
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
    
    <!-- 多环境配置 -->
    <springProfile name="default,prod">
        <!-- root -->
        <root level="INFO">
            <appender-ref ref="INFO_LOG_FILE"/>
            <appender-ref ref="ERROR_LOG_FILE"/>
        </root>
	</springProfile>
    
    <!-- 多环境配置 -->
    <springProfile name="dev,test">
        <!-- root -->
        <root level="DEBUG">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="DEBUG_LOG_FILE"/>
            <appender-ref ref="INFO_LOG_FILE"/>
            <appender-ref ref="WARN_LOG_FILE"/>
            <appender-ref ref="ERROR_LOG_FILE"/>
        </root>
	</springProfile>
</configuration>
```



### 其他

[详解root和logger]: https://blog.csdn.net/u012129558/article/details/79947477	"详解root和logger"

